---
title: 'Generate Inference Result'
sidebarTitle: "Generate"
description: "Execute an agent and automatically capture traces, latency, and metadata"
---

import AgentCallables from '/snippets/agent-callables.mdx';

## Overview

The `generate()` method is the recommended way to execute your agent when you want automatic trace collection, timing, and inference result creation. It handles the complete lifecycle:

1. Initializes trace collection
2. Executes your agent with timing measurement
3. Creates/updates the inference result with all metadata
4. Saves collected traces to the platform
5. Cleans up trace context (prevents memory leaks)

<Info>
  This is the recommended method for production use as it handles all trace lifecycle management automatically.
</Info>

## Agent Options

<AgentCallables />

## Parameters

<ParamField path="agent" type="AgentType" required>
  The agent function to execute. Supported signatures:
  - **Simple:** `(user_message: str) -> str` — receives last user message
  - **Chat History:** `(messages: list[dict]) -> str` — receives full chat history (OpenAI format)
  - **Structured:** `(input_data: AgentInput) -> AgentResponse` — structured input/output
  
  Both sync and async functions are supported. Use the structured signature when you need `usage_info`, `cost_info`, or `retrieval_context`.
</ParamField>

<ParamField path="session" type="Session" required>
  The session object to associate the inference result with. Obtain via `galtea.sessions.create()` or `galtea.sessions.get()`.
</ParamField>

<ParamField path="user_input" type="string" optional>
  The user's input message to send to the agent. If not provided and the session is test-based, the test case input will be used automatically. Required for production/monitoring sessions.
</ParamField>

<ParamField path="throw_if_empty_agent_response" type="bool" optional>
  If `True`, raises a `ValueError` when the agent returns an empty response. Defaults to `False`.
</ParamField>

## Returns

Returns an `InferenceResult` object with all captured data.

## Example

```python
# Define your agent function
def my_agent(user_message: str) -> str:
    return f"Response to: {user_message}"


inference_result = galtea.inference_results.generate(
    agent=my_agent, session=session, user_input="Generate something"
)
```

## What Gets Captured

The `generate()` method automatically captures and saves:

| Data | Source | Description |
|------|--------|-------------|
| **Input** | `user_input` parameter | The user's message |
| **Output** | `AgentResponse.content` | The agent's response |
| **Retrieval Context** | `AgentResponse.retrieval_context` | Context used (for RAG) |
| **Latency** | Measured | End-to-end execution time in ms |
| **Usage Info** | `AgentResponse.usage_info` | Token counts (if provided) |
| **Cost Info** | `AgentResponse.cost_info` | Cost data (if provided) |
| **Traces** | `@trace` decorators | All traced operations |

## Providing Usage and Cost Information

Your agent can return usage and cost information in the `AgentResponse`:

```python
@galtea.trace(name="main", type=TraceType.AGENT)
def my_agent_with_usage(input_data: AgentInput) -> AgentResponse:
    # Your agent logic...

    return AgentResponse(
        content="Response content",
        usage_info={
            "input_tokens": 150,
            "output_tokens": 75,
            "cache_read_input_tokens": 50,
        },
        cost_info={
            "cost_per_input_token": 0.00001,
            "cost_per_output_token": 0.00003,
            "cost_per_cache_read_input_token": 0.000001,
        },
    )
```

## Comparison with Manual Approach

| Feature | `generate()` | Manual with `set_context()` |
|---------|-------------|-----------------------------|
| Context initialization | Automatic | `set_context()` |
| Agent execution | Automatic | Manual call |
| Timing measurement | Automatic | Manual |
| Inference result | Auto-created | `inference_results.create()` |
| Trace export | Automatic | Automatic on `clear_context()` |
| Memory cleanup | Automatic | `clear_context()` |
| Error handling | Built-in | Manual try/finally |

<Tip>
  Use `generate()` for most use cases. Use manual `set_context()`/`clear_context()` only when you need to manage inference result creation separately or have complex multi-step workflows.
</Tip>

## Error Handling

If the agent raises an exception, `generate()` ensures trace context is cleaned up:

```python
def failing_agent(input_data: AgentInput) -> AgentResponse:
    raise ValueError("Agent failed intentionally")


try:
    result = galtea_client.inference_results.generate(
        agent=failing_agent, session=session_error, user_input="test"
    )
except Exception as e:
    # Trace context is automatically cleaned up
    print(f"Agent failed: {e}")
```

## Related Methods

- [Create Inference Result](/sdk/api/inference-result/create) - Manual creation
- [Trace Service](/sdk/api/trace/service) - Manual trace management
- [Simulating Conversations](/sdk/tutorials/simulating-conversations) - Multi-turn simulations
