---
title: 'Update Inference Result'
sidebarTitle: "Update"
description: "Update an existing inference result with agent output and metadata"
---

## Overview

The `update()` method allows you to modify an existing inference result after it has been created. This is useful when you need to add or update output, latency, token usage, or cost information.

## Method Signature

```python
galtea.inference_results.update(
    inference_result_id: str,
    output: Optional[str] = None,
    input: Optional[str] = None,
    retrieval_context: Optional[str] = None,
    latency: Optional[float] = None,
    input_tokens: Optional[int] = None,
    output_tokens: Optional[int] = None,
    cache_read_input_tokens: Optional[int] = None,
    tokens: Optional[int] = None,
    cost: Optional[float] = None,
    cost_per_input_token: Optional[float] = None,
    cost_per_output_token: Optional[float] = None,
    cost_per_cache_read_input_token: Optional[float] = None
) -> InferenceResult
```

## Parameters

<ParamField path="inference_result_id" type="string" required>
  The ID of the inference result to update.
</ParamField>

### Output Fields

<ParamField path="output" type="string">
  The generated output or response from the AI model.
</ParamField>

<ParamField path="input" type="string">
  The input text or prompt for the inference result.
</ParamField>

<ParamField path="retrieval_context" type="string">
  The context retrieved by a RAG system, if applicable.
</ParamField>

### Performance Fields

<ParamField path="latency" type="float">
  The time in milliseconds from request to response.
</ParamField>

### Usage Fields

<ParamField path="input_tokens" type="int">
  Number of input tokens sent to the model.
</ParamField>

<ParamField path="output_tokens" type="int">
  Number of output tokens generated by the model.
</ParamField>

<ParamField path="cache_read_input_tokens" type="int">
  Number of input tokens read from the cache.
</ParamField>

<ParamField path="tokens" type="int">
  Total tokens used in the model call.
</ParamField>

### Cost Fields

<ParamField path="cost" type="float">
  The total cost associated with the model call.
</ParamField>

<ParamField path="cost_per_input_token" type="float">
  Cost per input token sent to the model.
</ParamField>

<ParamField path="cost_per_output_token" type="float">
  Cost per output token generated by the model.
</ParamField>

<ParamField path="cost_per_cache_read_input_token" type="float">
  Cost per input token read from the cache.
</ParamField>

## Returns

Returns the updated `InferenceResult` object.

## Example

```python
inference_result = galtea.inference_results.update(
    inference_result_id=inference_result_id,
    output="Paris is the capital.",
    cost=0.0001,
)
```

## Use Cases

### Deferred Output Update

Create an inference result first, then update it after processing completes:

```python
# Create inference result with just input
user_input = "What is the weather today?"
inference_result = galtea.inference_results.create(
    session_id=session.id, input=user_input
)
if inference_result is None:
    raise ValueError("inference_result is None")

# Process with your model
start_time = time.time()
response = my_model_generate(user_input)
latency_ms = (time.time() - start_time) * 1000

# Update with output and metrics
galtea.inference_results.update(
    inference_result_id=inference_result.id, output=response, latency=latency_ms
)
```

### Adding Cost Information

Update an inference result with cost data after receiving billing info:

```python
galtea.inference_results.update(
    inference_result_id=inference_result.id,
    cost=0.0025,
    cost_per_input_token=0.00001,
    cost_per_output_token=0.00003,
)
```

## Notes

<Warning>
  Only include fields you want to update. Fields not specified will remain unchanged.
</Warning>

- Pass `None` explicitly to clear a field's value
- The `creditsUsed` field cannot be modified through this method

## Related Methods

- [Create Inference Result](/sdk/api/inference-result/create) - Create a new inference result
- [Generate Inference Result](/sdk/api/inference-result/generate) - Create with automatic trace collection
- [Get Inference Result](/sdk/api/inference-result/get) - Retrieve an inference result
